#!/bin/usr/python3


# Use example: python generate_ROI_results.py GIFNiftyNet.ctbl df_subids_filenames_densenet121_32ep.csv test_output_roi_results 

## Import libraries
import os
import argparse
import nibabel as nib
from nibabel.affines import apply_affine
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd
from helpers import makedir
#import numpy.linalg as npl


## Define useful functions to generate ROI results for each participant
def generate_one_subject_ROI_results(att_map, img_seg_or, img_affine, img_seg_or_affine, df_GIF_ROIs_numbers):
    # Get the matrix to convert coordinates from the final segmentation image transformed to the original segmentation image
    m_conversion = np.linalg.inv(img_affine).dot(img_seg_or_affine)
    # Get the mask from attention maps generated by Guided Grad-CAM
    mask = att_map > np.median(att_map)
    # Get the coordinates where it is True in the mask
    true_coords = np.argwhere(mask)
    # Get the brain ROIs numbers from converting True coordinates of each voxel from the final segmentation image to the original segmentation image
    brain_rois = []
    if img_seg_or.shape[0] == 1:
        max_x = img_seg_or.shape[1]-1
        max_y = img_seg_or.shape[2]-1
        max_z = img_seg_or.shape[3]-1
        for i in range(true_coords.shape[0]):
            img_coords_one_voxel = true_coords[i, :]
            seg_or_coordinates = apply_affine(m_conversion, img_coords_one_voxel)
            x = np.min([int(seg_or_coordinates[0]), max_x])
            y = np.min([int(seg_or_coordinates[1]), max_y])
            z = np.min([int(seg_or_coordinates[2]), max_z])
            brain_rois.append(img_seg_or[0, x, y, z])
    else:
        max_x = img_seg_or.shape[0]-1
        max_y = img_seg_or.shape[1]-1
        max_z = img_seg_or.shape[2]-1
        for i in range(true_coords.shape[0]):
            img_coords_one_voxel = true_coords[i, :]
            seg_or_coordinates = apply_affine(m_conversion, img_coords_one_voxel)
            x = np.min([int(seg_or_coordinates[0]), max_x])
            y = np.min([int(seg_or_coordinates[1]), max_y])
            z = np.min([int(seg_or_coordinates[2]), max_z])
            brain_rois.append(img_seg_or[x, y, z])
    # Count values of each region of interest
    vc = pd.Series(brain_rois).value_counts()
    # Get the size of each ROI from the coordinates 
    # to be able to normalize the results and get the significant areas    
    df_ROI_sizes = {"ROI_number": [], "Size": [], "Frequency": []}
    for n in df_GIF_ROIs_numbers.ROI_number.tolist():
        df_ROI_sizes["ROI_number"].append(n)
        df_ROI_sizes["Size"].append(np.sum(img_seg_or == n))
        if n in vc.index:
            df_ROI_sizes["Frequency"].append(vc[n])
        else:
            df_ROI_sizes["Frequency"].append(0)
    df_ROI_sizes = pd.DataFrame(df_ROI_sizes)
    df_ROI_sizes["Relative_frequency"] = df_ROI_sizes.Frequency / df_ROI_sizes.Size
    return df_ROI_sizes


if __name__=="__main__":
    # Load parameters
    parser = argparse.ArgumentParser(description='Example BIDS App entrypoint script.')
    parser.add_argument('GIF_ROIs_filename', help='The file containing the correspondance between RO numbers and names. Several numbers might not have corresponding names!')
    parser.add_argument('subids_files_filename', help='The csv file containing subids, dataset, label, att_map_filename, img_seg_filename, img_seg_original_filename.')
    parser.add_argument('output_dir', help='The directory where the results (all_ROIs_results.csv, train_ROIs_results.csv, val_ROIs_results.csv,test_ROIs_results.csv) should be stored.')
    args = parser.parse_args()
    output_dir = args.output_dir
    makedir(output_dir)
    # Load GIF ROIs  
    df_GIF_ROIs_numbers = pd.read_csv(args.GIF_ROIs_filename, sep=" ", header=None)
    df_GIF_ROIs_numbers.columns = ["ROI_number", "ROI_name", "coord_x", "coord_y", "coord_z", "color"]
    # Load subids and filenames
    df_subids_filenames = pd.read_csv(args.subids_files_filename)
    # LOOP over subjects
    for i in range(df_subids_filenames.shape[0]):
        #dataset = df_subids_filenames.iloc[i, :]["dataset"]
        label = df_subids_filenames.iloc[i, :]["label"]
        subid = df_subids_filenames.iloc[i, :]["SUB_ID"]
        print(subid)
        # get images and affine matrices
        img = nib.load(df_subids_filenames.iloc[i, :]["att_map_filename"])
        att_map = img.get_fdata()
        img.uncache()
        img = nib.load(df_subids_filenames.iloc[i, :]["img_seg_original_filename"])
        img_seg_or = img.get_fdata()
        img_seg_or_affine = img.affine
        img.uncache()
        img = nib.load(df_subids_filenames.iloc[i, :]["img_seg_filename"])
        img_affine = img.affine
        img.uncache()
        # generate results for the current subject
        df_ROI_freq_sizes = generate_one_subject_ROI_results(att_map, img_seg_or, img_affine, img_seg_or_affine, df_GIF_ROIs_numbers)
        #df_ROI_freq_sizes.to_csv("test_one_participant.csv")
        df_ROI_freq_sizes = df_ROI_freq_sizes.sort_values("ROI_number")
        df_ROI_freq_sizes.to_csv(os.path.join(output_dir, str(subid) + "_df_ROI_freq_sizes.csv"))
        ## go over the df_ROI_freq_sizes to fill the global results
